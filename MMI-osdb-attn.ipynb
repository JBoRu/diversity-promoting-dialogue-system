{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import preprocess\n",
    "from DataLoader import DataLoader\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter dataset\n",
    "\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "max_vocab_size = 20000\n",
    "max_sen, min_sen = 14, 3\n",
    "unk_most = 1\n",
    "reverse_flag = 1  # reverse the input sequence order Sutskever et al., 2014\n",
    "inverse_flag = 0  # MMI bidirection: train P(T|S) by inversing source and target\n",
    "\n",
    "dataStat = preprocess.dataPreProcess('dataset/open_subtitles_one.txt', max_vocab_size, max_sen, min_sen, unk_most, reverse_flag, inverse_flag) \n",
    "print(\"Number of total words:\", dataStat.numOfWords)\n",
    "\n",
    "wordCount = sorted(dataStat.word2cnt.values(), reverse=True)\n",
    "print(\"Dictionary cover ratio:\", sum(wordCount[:max_vocab_size-4]) / sum(wordCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad or cut input and output sentence\n",
    "\n",
    "def padding(source, maxLen):\n",
    "    return np.pad(source[:maxLen],(0,max(0,maxLen-len(source))),'constant')\n",
    "\n",
    "input_max_len, output_max_len = 15, 15\n",
    "\n",
    "pairsNum = len(dataStat.pairsInd)\n",
    "pairsLength = np.array([[len(l[0]), len(l[1])] for l in dataStat.pairsInd])\n",
    "upperLength = np.concatenate((np.ones((pairsNum,1), dtype=int)*input_max_len, \n",
    "                              np.ones((pairsNum,1), dtype=int)*output_max_len), axis=1)\n",
    "pairsLength = np.minimum(pairsLength,upperLength)\n",
    "pairsAligned = np.array([np.concatenate((padding(l[0], input_max_len), \n",
    "                                              padding(l[1], output_max_len))) for l in dataStat.pairsInd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = 'resume'\n",
    "\n",
    "ratios = [0.90, 0.05, 0.05]\n",
    "pairsNumTrain, pairsNumDeve = round(ratios[0]*pairsNum), round(ratios[1]*pairsNum)\n",
    "pairsNumTest = pairsNum - pairsNumTrain - pairsNumDeve\n",
    "\n",
    "if train_type=='restart':\n",
    "    deve_idxes = np.random.choice(pairsNum, pairsNumDeve, replace=False)\n",
    "    test_idxes = np.random.choice(list(set(np.arange(pairsNum)).difference(set(deve_idxes))), pairsNumTest, replace=False)\n",
    "    train_idxes = np.array(list(set(np.arange(pairsNum)).difference(set(deve_idxes)).difference(set(test_idxes))))\n",
    "#     np.save(\"parameter/pairsIdxesTriple_osdb_1_unk.npy\", (train_idxes, deve_idxes, test_idxes))\n",
    "else:\n",
    "    train_idxes, deve_idxes, test_idxes = np.load( \"parameter/pairsIdxesTriple_osdb_1_unk.npy\" )\n",
    "\n",
    "pairsAlignedTrain, pairsAlignedDeve, pairsAlignedTest = pairsAligned[train_idxes], pairsAligned[deve_idxes], pairsAligned[test_idxes]\n",
    "pairsLengthTrain, pairsLengthDeve, pairsLengthTest = pairsLength[train_idxes], pairsLength[deve_idxes], pairsLength[test_idxes]\n",
    "\n",
    "assert pairsNumTrain == len(train_idxes)\n",
    "assert pairsNumDeve == len(deve_idxes)\n",
    "assert pairsNumTest == len(test_idxes)\n",
    "    \n",
    "print(\"Total training pairs: \",pairsNumTrain)\n",
    "print(\"Total develop pairs: \",pairsNumDeve)\n",
    "print(\"Total test pairs: \",pairsNumTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tiny verification program\n",
    "\n",
    "# environment setup\n",
    "vocab_size = min(dataStat.numOfWords, max_vocab_size)\n",
    "hidden_size = 1000\n",
    "train_type = 'resume'\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "rnnEncoder = model.Encoder(embedding, vocab_size, 1, hidden_size, n_layers=2, bidirectional=False, variable_lengths=True)\n",
    "# rnnDecoder = Decoder(embedding, vocab_size, 1, hidden_size, n_layers=2, bidirectional=False)\n",
    "rnnDecoder = model.LuongAttnDecoderRNN('general_batch', embedding, hidden_size, vocab_size, n_layers=2)\n",
    "\n",
    "if train_type.lower()=='restart': pass\n",
    "elif train_type.lower()=='resume':\n",
    "    para_name = 'osdb_0605_50'\n",
    "    embedding.load_state_dict(torch.load('parameter/embeding_'+para_name+'.pt'))\n",
    "    rnnEncoder.load_state_dict(torch.load('parameter/encoder_'+para_name+'.pt'))\n",
    "    rnnDecoder.load_state_dict(torch.load('parameter/decoder_'+para_name+'.pt'))\n",
    "else: print(\"Please enter valid training type !\")\n",
    "\n",
    "if USE_CUDA:\n",
    "    rnnEncoder.cuda()\n",
    "    rnnDecoder.cuda()\n",
    "\n",
    "criterion = nn.NLLLoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer_encoder = optim.Adam(rnnEncoder.parameters(), learning_rate)\n",
    "optimizer_decoder = optim.Adam(rnnDecoder.parameters(), learning_rate)\n",
    "\n",
    "# initialize dataloader\n",
    "batch_size = 48\n",
    "trainLoader = DataLoader(pairsAlignedTrain, pairsLengthTrain, input_max_len, output_max_len)\n",
    "trainLoader.reset(batch_size)\n",
    "\n",
    "deveLoader = DataLoader(pairsAlignedDeve, pairsLengthDeve, input_max_len, output_max_len)\n",
    "deveLoader.reset(batch_size)\n",
    "\n",
    "testLoader = DataLoader(pairsAlignedTest, pairsLengthTest, input_max_len, output_max_len)\n",
    "testLoader.reset(batch_size)\n",
    "\n",
    "print(\"iteration per epoch:\", int(pairsNumTrain/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneMask(outputs_record, lengths):\n",
    "    batch_size = lengths.size(0)\n",
    "    # prepare\n",
    "    comp = torch.arange(output_max_len).view(-1,1)\n",
    "    if USE_CUDA: comp = comp.cuda()\n",
    "    comp_ex = comp.repeat(1,vocab_size).repeat(batch_size,1,1)\n",
    "    # generate\n",
    "    l_ex = lengths[:,1].view(batch_size,-1).repeat(1,vocab_size).view(batch_size,1,-1)\n",
    "    if USE_CUDA: l_ex = l_ex.type(torch.cuda.FloatTensor)\n",
    "    else: l_ex = l_ex.type(torch.FloatTensor)\n",
    "    mask = comp_ex < l_ex\n",
    "    if USE_CUDA: mask = mask.type(torch.cuda.FloatTensor)\n",
    "    else: mask = mask.type(torch.FloatTensor)\n",
    "    return torch.mul(mask, outputs_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneEpoch():\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_ind in range(int(pairsNum/batch_size)+1):\n",
    "    \n",
    "        # prepare mini-batch data\n",
    "        try:\n",
    "            inputs, targets, lengths = trainLoader.getMiniBatch()\n",
    "        except Exception as e:\n",
    "            # print('GG...')\n",
    "            break\n",
    "        else:\n",
    "            # print('Good!')\n",
    "\n",
    "            # Zero gradients of both optimizers\n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "\n",
    "            # encoding and decoding\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            hid_init = rnnEncoder.init_hidden(batch_size)\n",
    "            out_enc, hid_enc = rnnEncoder.forward(inputs,lengths[:,0],hid_init)\n",
    "            encoder_outputs = torch.transpose(out_enc,0,1) # convery batch_first to seqlen_first\n",
    "            \n",
    "            # Prepare decoder input and outputs\n",
    "            decoder_input = Variable(torch.LongTensor([dataStat.word2ind['SOS']] * batch_size))\n",
    "            decoder_hidden = hid_enc[:rnnDecoder.n_layers] # Use last (forward/concatenate) hidden state from encoder\n",
    "            if USE_CUDA:\n",
    "                decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Run through decoder one time step at a time\n",
    "            all_decoder_outputs, decoder_hidden, decoder_attn = rnnDecoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            for t in range(output_max_len-1): # output_max_len\n",
    "                decoder_input = targets[:,t] # Next input is current target\n",
    "                decoder_output, decoder_hidden, decoder_attn = rnnDecoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                all_decoder_outputs = torch.cat((all_decoder_outputs, decoder_output), 0) # Store this step's outputs [1,B,N]\n",
    "                \n",
    "            outputs_mask = geneMask(torch.transpose(all_decoder_outputs,0,1), lengths)\n",
    "            loss = criterion(torch.transpose(outputs_mask,1,2), targets)\n",
    "            #print(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            clip = 5\n",
    "            norm_encoder = torch.nn.utils.clip_grad_norm_(rnnEncoder.parameters(), clip)\n",
    "            norm_decoder = torch.nn.utils.clip_grad_norm_(rnnDecoder.parameters(), clip)\n",
    "\n",
    "            optimizer_encoder.step()\n",
    "            optimizer_decoder.step()\n",
    "            \n",
    "            running_loss += float(loss)\n",
    "            \n",
    "            if (batch_ind+1)%1000 == 0:\n",
    "                print(\"iteration\", batch_ind+1, \" ---- running loss:\", running_loss/batch_ind)\n",
    "                \n",
    "            if batch_ind+1 == 5000: break\n",
    "    \n",
    "    print(\"\\tnorm:\\t\", float(norm_encoder), float(norm_decoder))\n",
    "    \n",
    "    return running_loss/batch_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneEpochEval():\n",
    "\n",
    "    lossPool = []\n",
    "    \n",
    "    loaderPool = [deveLoader, testLoader]\n",
    "\n",
    "    for loader in loaderPool:\n",
    "        for batch_ind in range(int(pairsNum/batch_size)+1):\n",
    "            # prepare mini-batch data\n",
    "            try:\n",
    "                inputs, targets, lengths = loader.getMiniBatch()\n",
    "            except Exception as e:\n",
    "                # print('GG...')\n",
    "                break\n",
    "            else:\n",
    "                # print('Good!')\n",
    "\n",
    "                # Zero gradients of both optimizers\n",
    "                optimizer_encoder.zero_grad()\n",
    "                optimizer_decoder.zero_grad()\n",
    "\n",
    "                # encoding and decoding\n",
    "                inputs, targets = Variable(inputs), Variable(targets)\n",
    "                hid_init = rnnEncoder.init_hidden(batch_size)\n",
    "                out_enc, hid_enc = rnnEncoder.forward(inputs,lengths[:,0],hid_init)\n",
    "                encoder_outputs = torch.transpose(out_enc,0,1) # convery batch_first to seqlen_first\n",
    "\n",
    "                # Prepare decoder input and outputs\n",
    "                decoder_input = Variable(torch.LongTensor([dataStat.word2ind['SOS']] * batch_size))\n",
    "                decoder_hidden = hid_enc[:rnnDecoder.n_layers] # Use last (forward/concatenate) hidden state from encoder\n",
    "                if USE_CUDA:\n",
    "                    decoder_input = decoder_input.cuda()\n",
    "\n",
    "                # Run through decoder one time step at a time\n",
    "                all_decoder_outputs, decoder_hidden, decoder_attn = rnnDecoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                for t in range(output_max_len-1): # output_max_len\n",
    "                    decoder_input = targets[:,t] # Next input is current target\n",
    "                    decoder_output, decoder_hidden, decoder_attn = rnnDecoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                    all_decoder_outputs = torch.cat((all_decoder_outputs, decoder_output), 0) # Store this step's outputs [1,B,N]\n",
    "\n",
    "                outputs_mask = geneMask(torch.transpose(all_decoder_outputs,0,1), lengths)\n",
    "                loss = criterion(torch.transpose(outputs_mask,1,2), targets)\n",
    "\n",
    "                if batch_ind+1 == 100: break\n",
    "                    \n",
    "        lossPool.append(float(loss))\n",
    "    \n",
    "    return lossPool[0], lossPool[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePara(epoch):\n",
    "    para_name = 'osdb_0605_'+str(epoch)\n",
    "    torch.save(embedding.state_dict(),'parameter/embeding_'+para_name+'.pt')\n",
    "    torch.save(rnnEncoder.state_dict(),'parameter/encoder_'+para_name+'.pt')\n",
    "    torch.save(rnnDecoder.state_dict(),'parameter/decoder_'+para_name+'.pt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnEncoder.train()\n",
    "rnnDecoder.train()\n",
    "\n",
    "print(\"Begin training...\")\n",
    "print(\"Learning rate = \", learning_rate)\n",
    "print(time.asctime( time.localtime(time.time()) ))\n",
    "\n",
    "for i in range(10):\n",
    "    trainLoader.reset(batch_size)\n",
    "    loss = oneEpoch()\n",
    "    if (i+1)%1==0:\n",
    "        print('Epoch:', i+1, '\\tLoss:',loss)\n",
    "        print(time.asctime( time.localtime(time.time()) ))\n",
    "    if (i+1)%10==0:\n",
    "        savePara(i+1+0)\n",
    "#     # please run evaluate section first\n",
    "#     if (i+1)%2==0:\n",
    "#         score_train,paths_train = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda=0, threshold=0, loader=trainLoader, display=0)\n",
    "#         score_deve,paths_deve = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda=0, threshold=0, loader=deveLoader, display=0)\n",
    "#         score_test,paths_test = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda=0, threshold=0, loader=testLoader, display=0)\n",
    "#         scores.append((score_train, score_deve, score_test))\n",
    "#         print('BLEU score (train, deve, test):', score_train, score_deve, score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Language Model: P(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct P(target) language model\n",
    "\n",
    "freqLM = {}\n",
    "\n",
    "for i in range(pairsNumTrain):\n",
    "    length = pairsLengthTrain[i][1]\n",
    "    rsps = pairsAlignedTrain[i][input_max_len:input_max_len+length]\n",
    "    dic = freqLM\n",
    "    for j in range(min(5,length)):\n",
    "        if rsps[j] not in dic: dic[rsps[j]] = [1,{}]\n",
    "        else: dic[rsps[j]][0] += 1\n",
    "        dic = dic[rsps[j]][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size: B x S\n",
    "def conProb(prefix_batch):\n",
    "    this_batch_size = len(prefix_batch)\n",
    "    count_matrix = np.ones((this_batch_size, vocab_size))\n",
    "    for b, prefix in enumerate(prefix_batch):\n",
    "        count_array = np.ones(vocab_size)\n",
    "        dic = freqLM\n",
    "        try:\n",
    "            for ind in prefix:\n",
    "                dic = dic[ind][1]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        else:\n",
    "            for key in dic:\n",
    "                count_array[key] += dic[key][0]\n",
    "        total_freq = np.sum(count_array)\n",
    "        count_matrix[b] = (count_array/total_freq)\n",
    "    dist_tensor = torch.FloatTensor(np.log(count_matrix))\n",
    "    if USE_CUDA: dist_tensor = dist_tensor.cuda()\n",
    "    return dist_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute by BLEU and distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnEncoder.eval()\n",
    "rnnDecoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate into natural language\n",
    "\n",
    "def showResult(ind_seq, reverse=False):\n",
    "    token_list = []\n",
    "    for i in ind_seq:\n",
    "        if i == dataStat.word2ind['EOS']: break\n",
    "        token_list.append(dataStat.ind2word[i])\n",
    "    return ' '.join(token_list[::-1]) if reverse else  ' '.join(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# greedy search, mainly for debug\n",
    "\n",
    "def topOneDecode(decoder, decoder_hidden, encoder_outputs, stat, max_length=output_max_len):\n",
    "\n",
    "    decoder_input = torch.LongTensor([SOS_token]).view(1,-1)\n",
    "    if USE_CUDA: \n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_hidden = decoder_hidden.cuda()\n",
    "\n",
    "    decoded_words = []\n",
    "    \n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        # print(decoder_attn)\n",
    "        \n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append(ni.item())\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(ni.item())\n",
    "\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = trainLoader\n",
    "\n",
    "batch_size = 1\n",
    "loader.reset(batch_size)\n",
    "inputs, targets, lengths = loader.getMiniBatch()\n",
    "\n",
    "# encoding and decoding\n",
    "hid_init = rnnEncoder.init_hidden(batch_size)\n",
    "out_enc, hid_enc = rnnEncoder.forward(inputs,lengths[:,0],hid_init)\n",
    "decoder_hidden = hid_enc[:rnnDecoder.n_layers]\n",
    "encoder_outputs = torch.transpose(out_enc,0,1) # convery batch_first to seqlen_first\n",
    "\n",
    "trace = topOneDecode(rnnDecoder, decoder_hidden, encoder_outputs, dataStat, max_length=output_max_len)\n",
    "\n",
    "print(\"Message:\\t\", showResult(inputs.data[0].cpu().numpy(), reverse=True))\n",
    "print(\"Response:\\t\", showResult(trace))\n",
    "if targets is not None:\n",
    "    print(\"Teaching:\\t\", showResult(targets.data[0].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamDecodeBatch(decoder, decoder_hidden, encoder_outputs, voc, beam_size, lamda, threshold, max_length=output_max_len):\n",
    "    terminal_sentences, prev_top_sentences, next_top_sentences = [], [], []\n",
    "    prev_top_sentences.append(Sentence(decoder_hidden))\n",
    "    for _ in range(max_length-1):\n",
    "        this_batch_size = len(prev_top_sentences)\n",
    "        if this_batch_size > 0:\n",
    "            decoder_input = torch.LongTensor([[sentence.last_idx] for sentence in prev_top_sentences])\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "            decoder_hidden_batch = prev_top_sentences[0].decoder_hidden\n",
    "            for i in range(1,this_batch_size):\n",
    "                decoder_hidden_batch = torch.cat((decoder_hidden_batch, prev_top_sentences[i].decoder_hidden), dim=1)\n",
    "            encoder_outputs_batch = encoder_outputs.repeat(1,this_batch_size,1)\n",
    "            \n",
    "            decoder_output, decoder_hidden_batch, decoder_attn = decoder(decoder_input, decoder_hidden_batch, encoder_outputs_batch)\n",
    "            \n",
    "            # apply MMI anti-language model\n",
    "            if len(prev_top_sentences[0].sentence_idxes)<threshold:\n",
    "                LM_output = conProb([[int(idx) for idx in sentence.sentence_idxes] for sentence in prev_top_sentences])\n",
    "                decoder_output -= lamda*LM_output.view(1,this_batch_size,-1)\n",
    "            \n",
    "            topv_batch, topi_batch = decoder_output.topk(beam_size) # [1,B,k]\n",
    "            for b in range(this_batch_size):\n",
    "                sentence = prev_top_sentences[b]\n",
    "                topi, topv = topi_batch[0][b], topv_batch[0][b]\n",
    "                decoder_hidden = decoder_hidden_batch[:,b].unsqueeze(1)\n",
    "                term, top = sentence.addTopk(topi, topv, decoder_hidden, beam_size, voc)\n",
    "                terminal_sentences.extend(term)\n",
    "                next_top_sentences.extend(top)\n",
    "            \n",
    "        next_top_sentences.sort(key=lambda s: s.getScore(), reverse=True)\n",
    "        prev_top_sentences = next_top_sentences[:beam_size]\n",
    "        next_top_sentences = []\n",
    "\n",
    "    terminal_sentences += [sentence.toWordScore(voc) for sentence in prev_top_sentences]\n",
    "    terminal_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    n = min(len(terminal_sentences), 32)  # N-best list\n",
    "    return terminal_sentences[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, decoder_hidden, last_idx=SOS_token, sentence_idxes=[], sentence_scores=[]):\n",
    "        if(len(sentence_idxes) != len(sentence_scores)):\n",
    "            raise ValueError(\"length of indexes and scores should be the same\")\n",
    "        self.decoder_hidden = decoder_hidden\n",
    "        self.last_idx = last_idx\n",
    "        self.sentence_idxes =  sentence_idxes\n",
    "        self.sentence_scores = sentence_scores\n",
    "\n",
    "    def getScore(self, mode='avg', gamma=0.0):\n",
    "        if len(self.sentence_scores) == 0:\n",
    "            print(\"sentence of length 0\")\n",
    "            return torch.tensor(-999).float().cuda() if USE_CUDA else torch.tensor(-999).float()\n",
    "        if mode=='avg':\n",
    "            res = sum(self.sentence_scores) / len(self.sentence_scores)\n",
    "        else:\n",
    "            res = sum(self.sentence_scores) + gamma*len(self.sentence_scores)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def addTopk(self, topi, topv, decoder_hidden, beam_size, voc):\n",
    "        terminates, sentences = [], []\n",
    "        \n",
    "        topi, topv = topi.squeeze(), topv.squeeze()  # get data out of batch\n",
    "        \n",
    "        for i in range(beam_size):\n",
    "            if topi[i] == EOS_token:\n",
    "                terminates.append(([int(idx) for idx in self.sentence_idxes] + [EOS_token],\n",
    "                                   self.getScore())) # tuple(word_list, score_float)\n",
    "                continue\n",
    "            idxes = self.sentence_idxes[:] # pass by value\n",
    "            scores = self.sentence_scores[:] # pass by value\n",
    "            idxes.append(topi[i])\n",
    "            scores.append(topv[i])\n",
    "            sentences.append(Sentence(decoder_hidden, topi[i], idxes, scores))\n",
    "        return terminates, sentences\n",
    "\n",
    "    def toWordScore(self, voc):\n",
    "        words = []\n",
    "        for i in range(len(self.sentence_idxes)):\n",
    "            if self.sentence_idxes[i] == EOS_token:\n",
    "                words.append(EOS_token)\n",
    "            else:\n",
    "                words.append(int(self.sentence_idxes[i]))\n",
    "        if self.sentence_idxes[-1] != EOS_token:\n",
    "            words.append(EOS_token)\n",
    "        return (words, self.getScore())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "loader = trainLoader\n",
    "loader.reset(batch_size)\n",
    "inputs, targets, lengths = loader.getMiniBatch()\n",
    "\n",
    "# encoding and decoding\n",
    "hid_init = rnnEncoder.init_hidden(batch_size)\n",
    "out_enc, hid_enc = rnnEncoder.forward(inputs,lengths[:,0],hid_init)\n",
    "decoder_hidden = hid_enc[:rnnDecoder.n_layers]\n",
    "encoder_outputs = torch.transpose(out_enc,0,1) # convery batch_first to seqlen_first\n",
    "\n",
    "path_beam = beamDecodeBatch(rnnDecoder, decoder_hidden, encoder_outputs, dataStat, beam_size=3, lamda=0, threshold=0)  # return list of tuples: (path, score)\n",
    "for p in path_beam: print(float(p[1]), '\\t', showResult(p[0]))\n",
    "\n",
    "print(\"Message:\\t\", showResult(inputs.data[0].cpu().numpy(), reverse=True))\n",
    "print(\"Response:\\t\", showResult(path_beam[0][0]))\n",
    "if targets is not None:\n",
    "    print(\"Teaching:\\t\", showResult(targets.data[0].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input, length, encoder, decoder, beam_size, lamda=0.0, threshold=0, verbose=False):\n",
    "    # encoding and decoding\n",
    "    hid_init = encoder.init_hidden(batch_size = 1)\n",
    "    out_enc, hid_enc = encoder.forward(input.view(1,-1),length.view(1),hid_init)\n",
    "    decoder_hidden = hid_enc[:rnnDecoder.n_layers]\n",
    "    encoder_outputs = torch.transpose(out_enc,0,1) # convery batch_first to seqlen_first\n",
    "\n",
    "    if beam_size==0:\n",
    "        path = topOneDecode(decoder, decoder_hidden, dataStat, max_length=15)  # return path in list\n",
    "        return path\n",
    "    else:\n",
    "        path_beam = beamDecodeBatch(decoder, decoder_hidden, encoder_outputs, dataStat, beam_size, lamda, threshold)  # return list of tuples: (path, score)\n",
    "        if verbose:\n",
    "            for p in path_beam: print(float(p[1]), '\\t', showResult(p[0]))\n",
    "        return path_beam[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSample(encoder, decoder, beam_size=5, lamda=0.0, threshold=0, verbose=True, myQuery=''):\n",
    "    \n",
    "    if myQuery == '':\n",
    "        print(\"Blank Input\")\n",
    "        return -1\n",
    "    else:\n",
    "        # feed in customized tokens\n",
    "        sample_query = myQuery.lower()\n",
    "        sample_query_ind, _ = preprocess.encodePair(dataStat, (sample_query,'.'),reverse=True)\n",
    "        sample_query_tensor = torch.LongTensor([padding(sample_query_ind, input_max_len)])\n",
    "        sample_query_length = torch.LongTensor([len(sample_query_ind)])\n",
    "        if USE_CUDA: input, length, target = sample_query_tensor.cuda(), sample_query_length.cuda(), None\n",
    "        \n",
    "    trace = generate(input, length, encoder, decoder, beam_size, lamda, threshold, verbose=True)\n",
    "    if verbose:\n",
    "        print(\"Message:\\t\", showResult(input.data[0].cpu().numpy(), reverse=True))\n",
    "        print(\"Response:\\t\", showResult(trace))\n",
    "        if target is not None:\n",
    "            print(\"Teaching:\\t\", showResult(target.data[0].cpu().numpy()))\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "def evaluateSentence(encoder, decoder, beam_size=1, lamda=0.0, threshold=0, loader=trainLoader, display=False):\n",
    "    \n",
    "    loader.reset(1)\n",
    "    data_length = loader.dataLength\n",
    "    responses = []\n",
    "    total_score = 0\n",
    "    sample_length = min(2000, data_length)\n",
    "    \n",
    "    for i in range(sample_length):\n",
    "        inputs, targets, lengths = loader.getMiniBatch()\n",
    "        input, length, target = inputs, lengths[0][0], targets\n",
    "\n",
    "        trace = generate(input, length, encoder, decoder, beam_size, lamda, threshold)\n",
    "        responses.append(trace)\n",
    "                \n",
    "        length_ref = lengths[0][1]\n",
    "        references = [[target.data[0].tolist()[:int(length_ref)]]]\n",
    "        candidates = [trace]\n",
    "        score = corpus_bleu(references, candidates, smoothing_function=chencherry.method1)\n",
    "        total_score += score\n",
    "        \n",
    "        if display and (i+1)%int(sample_length/10)==0: print(\"complete\",int(100*(i+1)/sample_length),\"%\")\n",
    "        \n",
    "    return total_score/i, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "def evaluateCorpus(encoder, decoder, beam_size=1, lamda=0.0, threshold=0, loader=trainLoader, weights=[1,0,0,0], display=False):\n",
    "    \n",
    "    loader.reset(1)\n",
    "    data_length = loader.dataLength\n",
    "    sample_length = min(400, data_length)\n",
    "    \n",
    "    references = []\n",
    "    candidates = []\n",
    "    responses = []\n",
    "    \n",
    "    for i in range(sample_length):\n",
    "        inputs, targets, lengths = loader.getMiniBatch()\n",
    "        input, length, target = inputs, lengths[0][0], targets\n",
    "\n",
    "        trace = generate(input, length, encoder, decoder, beam_size, lamda, threshold)\n",
    "        responses.append(trace)\n",
    "                \n",
    "        length_ref = lengths[0][1]\n",
    "        references.append([target.data[0].tolist()[:int(length_ref)]])\n",
    "        candidates.append(trace)\n",
    "        \n",
    "        if display and (i+1)%int(sample_length/10)==0: print(\"complete\",int(100*(i+1)/sample_length),\"%\")\n",
    "        \n",
    "    score = corpus_bleu(references, candidates, weights=weights, smoothing_function=chencherry.method1)\n",
    "    \n",
    "    return score, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinct evaluation\n",
    "\n",
    "import nltk\n",
    "\n",
    "def distinctEval(all_paths):\n",
    "\n",
    "    response_ugm = set([])\n",
    "    response_bgm = set([])        \n",
    "    response_len = sum([len(p) for p in all_paths])\n",
    "\n",
    "    for path in all_paths:\n",
    "        for u in path:\n",
    "            response_ugm.add(u)\n",
    "        for b in list(nltk.bigrams(path)):\n",
    "            response_bgm.add(b)\n",
    "\n",
    "    print(\"total length of response:\", response_len)\n",
    "    print(\"distinct unigrams:\", len(response_ugm)/response_len)\n",
    "    print(\"distinct bigrams:\", len(response_bgm)/response_len)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateSample(rnnEncoder, rnnDecoder, beam_size=2, lamda=0.5, threshold=2, verbose=True, myQuery='you better stay right there boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "score, responses = evaluateCorpus(rnnEncoder, rnnDecoder, beam_size=2, lamda=0.0, threshold=0, loader=deveLoader, display=True)\n",
    "distinctEval(responses)\n",
    "print('score:', score)\n",
    "print('average length:', sum([len(r) for r in responses])/len(responses))\n",
    "\n",
    "time_end = time.time()\n",
    "print(\"complete time:\", time_end-time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline -- gamma = 0, beam = 2\n",
    "lamda_list = [0.1,0.2,0.4]\n",
    "thres_list = [1,2]\n",
    "score_list = [[],[],[]]\n",
    "\n",
    "for threshold in thres_list:\n",
    "    for lamda in lamda_list:\n",
    "        print(time.asctime( time.localtime(time.time()) ))\n",
    "        print('threshold: ', threshold, '\\nlambda: ', lamda)\n",
    "        score_train,_ = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda, threshold, loader=trainLoader, display=0)\n",
    "        score_deve,paths_deve = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda, threshold, loader=deveLoader, display=0)\n",
    "        score_test,paths_test = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda, threshold, loader=testLoader, display=0)\n",
    "        score_list[0].append(score_train)\n",
    "        score_list[1].append(score_deve)\n",
    "        score_list[2].append(score_test)\n",
    "        print(score_train, score_deve, score_test)\n",
    "        distinctEval(paths_deve)\n",
    "        distinctEval(paths_test)\n",
    "\n",
    "# score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline -- gamma = 0, beam = 2\n",
    "lamda_list = [0.1,0.2,0.4]\n",
    "thres_list = [1,2]\n",
    "score_list = [[],[],[]]\n",
    "\n",
    "for threshold in thres_list:\n",
    "    for lamda in lamda_list:\n",
    "        print(time.asctime( time.localtime(time.time()) ))\n",
    "        print('threshold: ', threshold, '\\nlambda: ', lamda)\n",
    "        score_train,_ = evaluateCorpus(rnnEncoder, rnnDecoder, 4, lamda, threshold, loader=trainLoader, display=0)\n",
    "        score_deve,paths_deve = evaluateCorpus(rnnEncoder, rnnDecoder, 4, lamda, threshold, loader=deveLoader, display=0)\n",
    "        score_test,paths_test = evaluateCorpus(rnnEncoder, rnnDecoder, 4, lamda, threshold, loader=testLoader, display=0)\n",
    "        score_list[0].append(score_train)\n",
    "        score_list[1].append(score_deve)\n",
    "        score_list[2].append(score_test)\n",
    "        print(score_train, score_deve, score_test)\n",
    "        distinctEval(paths_deve)\n",
    "        distinctEval(paths_test)\n",
    "\n",
    "# score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-prrameter tuning -- gamma is set as 0.25\n",
    "lamda_list = [-0.2,0,0.2,0.5]\n",
    "thres_list = [1,2]\n",
    "score_list = [[],[],[]]\n",
    "\n",
    "for threshold in thres_list:\n",
    "    for lamda in lamda_list:\n",
    "        print(time.asctime( time.localtime(time.time()) ))\n",
    "        print(threshold, '\\t', lamda)\n",
    "        score_train,_ = evaluateCorpus(rnnEncoder, rnnDecoder,2, lamda, threshold, loader=trainLoader, display=0)\n",
    "        score_deve,paths_deve = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda, threshold, loader=deveLoader, display=0)\n",
    "        score_test,paths_test = evaluateCorpus(rnnEncoder, rnnDecoder, 2, lamda, threshold, loader=testLoader, display=0)\n",
    "        score_list[0].append(score_train)\n",
    "        score_list[1].append(score_deve)\n",
    "        score_list[2].append(score_test)\n",
    "        print(score_train, score_deve, score_test)\n",
    "        distinctEval(paths_deve)\n",
    "        distinctEval(paths_test)\n",
    "\n",
    "# score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-prrameter tuning\n",
    "lamda_list = [0.1, 0.3]  # gamma = 0.2\n",
    "thres_list = [2, 3]\n",
    "score_list = [[],[],[]]\n",
    "\n",
    "for threshold in thres_list:\n",
    "    for lamda in lamda_list:\n",
    "        print(time.asctime( time.localtime(time.time()) ))\n",
    "        print(threshold, '\\t', lamda)\n",
    "        score_train,_ = evaluateCorpus(rnnEncoder, rnnDecoder,5, lamda, threshold, loader=trainLoader, display=0)\n",
    "        score_deve,paths_deve = evaluateCorpus(rnnEncoder, rnnDecoder, 5, lamda, threshold, loader=deveLoader, display=0)\n",
    "        score_test,paths_test = evaluateCorpus(rnnEncoder, rnnDecoder, 5, lamda, threshold, loader=testLoader, display=0)\n",
    "        score_list[0].append(score_train)\n",
    "        score_list[1].append(score_deve)\n",
    "        score_list[2].append(score_test)\n",
    "        print(score_train, score_deve, score_test)\n",
    "        distinctEval(paths_deve)\n",
    "        distinctEval(paths_test)\n",
    "\n",
    "# score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-prrameter tuning\n",
    "lamda_list = [0.2, 0.4]  # gamma = 0.4\n",
    "thres_list = [1, 2]\n",
    "score_list = [[],[],[]]\n",
    "\n",
    "for threshold in thres_list:\n",
    "    for lamda in lamda_list:\n",
    "        print(time.asctime( time.localtime(time.time()) ))\n",
    "        print(threshold, '\\t', lamda)\n",
    "        score_train,_ = evaluateCorpus(rnnEncoder, rnnDecoder,5, lamda, threshold, loader=trainLoader, display=0)\n",
    "        score_deve,paths_deve = evaluateCorpus(rnnEncoder, rnnDecoder, 5, lamda, threshold, loader=deveLoader, display=0)\n",
    "        score_test,paths_test = evaluateCorpus(rnnEncoder, rnnDecoder, 5, lamda, threshold, loader=testLoader, display=0)\n",
    "        score_list[0].append(score_train)\n",
    "        score_list[1].append(score_deve)\n",
    "        score_list[2].append(score_test)\n",
    "        print(score_train, score_deve, score_test)\n",
    "        distinctEval(paths_deve)\n",
    "        distinctEval(paths_test)\n",
    "\n",
    "# score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
